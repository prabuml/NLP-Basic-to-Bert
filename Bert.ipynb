{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Bert.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fceaa4b2961c4a7d8d6f0b160fabe43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63f3ed0ae9b5420d9d09252bb7a6a0d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b0adc75c4da4ce5aec8ccdee58a1a5d",
              "IPY_MODEL_449b5b038e6f47619fad2a7d23ed32ad"
            ]
          }
        },
        "63f3ed0ae9b5420d9d09252bb7a6a0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b0adc75c4da4ce5aec8ccdee58a1a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec304675b7d8477cb92d856faeeddfa7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef73c568cdfa44caa360196042f29e24"
          }
        },
        "449b5b038e6f47619fad2a7d23ed32ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de388cb03bea446c866f6d5ac4aee771",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 5000/5000 [19:14&lt;00:00,  4.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06c241756172408b8cf72064afee8c7a"
          }
        },
        "ec304675b7d8477cb92d856faeeddfa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef73c568cdfa44caa360196042f29e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de388cb03bea446c866f6d5ac4aee771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06c241756172408b8cf72064afee8c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fa2881ff349451da51abfaf168c14ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4deed147c57043968338de2054a02cc3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d3853144ad349ceb3d81c4f99a93496",
              "IPY_MODEL_bc073690aba642dca728aa7287661c85"
            ]
          }
        },
        "4deed147c57043968338de2054a02cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d3853144ad349ceb3d81c4f99a93496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbeb99f78dcf4130972727373cb62312",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 6250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6250,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9e7aa7c8a644d36bb01936062ea3bfa"
          }
        },
        "bc073690aba642dca728aa7287661c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00385e885a3a428a98fb29f78381ecf4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 6250/6250 [07:21&lt;00:00, 14.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_704b970870a24f9ab933ba2377df6172"
          }
        },
        "cbeb99f78dcf4130972727373cb62312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9e7aa7c8a644d36bb01936062ea3bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00385e885a3a428a98fb29f78381ecf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "704b970870a24f9ab933ba2377df6172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYTCED-1p0sC",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/prabuscihero/NLP-Basic-to-Bert/blob/master/Bert.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQZYLrEUXBjk",
        "colab_type": "text"
      },
      "source": [
        "## Model - Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yyggmf5p0sE",
        "colab_type": "code",
        "outputId": "5e71f0d6-73a0-4e1a-f490-c6c2d304225c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "\n",
        "!pip install transformers==2.1.0\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, \n",
        "                          BertConfig, BertForSequenceClassification, BertTokenizer)\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import AdamW,WarmupLinearSchedule\n",
        "from tqdm import tqdm_notebook as tn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/e5/4fb8a6215608c4036b6dd16613268a4b8958c20e4249d141e621e7f2e146/transformers-2.1.0-py3-none-any.whl (313kB)\n",
            "\r\u001b[K     |█                               | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.0) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.0) (4.28.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.0) (2019.12.9)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.0) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.0) (1.10.40)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.0) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.0) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.0) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.0) (1.13.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.0) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers==2.1.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers==2.1.0) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=8f15af9166b463f886c55bb74d45e61e4b117eacf6b569d359c8d60ff9fe309e\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.85 transformers-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcGR-b67p0sH",
        "colab_type": "code",
        "outputId": "bcc24ae3-eeaa-49cc-ff85-ced193240412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvljOXXLqemH",
        "colab_type": "code",
        "outputId": "8c224f23-75a7-4f36-cb15-03ed672e7a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/gdrive/My Drive/Colab Notebooks/NLP-Basic-to-Bert'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/NLP-Basic-to-Bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OalqpA2Pp0sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the training data\n",
        "train_df_full = pd.read_csv('training_data.csv')\n",
        "test_df = pd.read_csv('testing_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmJY6xJGp0sN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create train and validation set\n",
        "train_df, valid_df, train_labels, valid_labels = train_test_split(train_df_full, train_df_full.user_rating, random_state=42, stratify=train_df_full.user_rating,test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIWndZwkp0sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert text to transformer features for Transformer models\n",
        "\n",
        "def convert_text_to_features(examples, tokenizer,\n",
        "                                      max_length=512,\n",
        "                                      pad_on_left=False,\n",
        "                                      pad_token=0,\n",
        "                                      pad_token_segment_id=0,\n",
        "                                      mask_padding_with_zero=True):\n",
        "    \"\"\"\n",
        "    Loads a data file into a list of ``InputFeatures``\n",
        "    Args:\n",
        "        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
        "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
        "        max_length: Maximum example length\n",
        "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
        "        pad_token: Padding token\n",
        "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
        "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
        "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
        "            actual values)\n",
        "    Returns:\n",
        "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
        "        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n",
        "        a list of task-specific ``InputFeatures`` which can be fed to the model.\n",
        "    \"\"\"\n",
        "    features = [[],[],[]]\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            print(\"Writing example %d\" % (ex_index))\n",
        "\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            example,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "        )\n",
        "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_length - len(input_ids)\n",
        "        if pad_on_left:\n",
        "            input_ids = ([pad_token] * padding_length) + input_ids\n",
        "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
        "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
        "        else:\n",
        "            input_ids = input_ids + ([pad_token] * padding_length)\n",
        "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "        assert len(input_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_ids), max_length)\n",
        "        assert len(attention_mask) == max_length, \"Error with input length {} vs {}\".format(len(attention_mask), max_length)\n",
        "        assert len(token_type_ids) == max_length, \"Error with input length {} vs {}\".format(len(token_type_ids), max_length)\n",
        "\n",
        "        if ex_index < 1:\n",
        "            print(\"*** Example ***\")\n",
        "            print(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            print(\"attention_mask: %s\" % \" \".join([str(x) for x in attention_mask]))\n",
        "            print(\"token_type_ids: %s\" % \" \".join([str(x) for x in token_type_ids]))\n",
        "\n",
        "        features[0].append(input_ids)\n",
        "        features[1].append(attention_mask)\n",
        "        features[2].append(token_type_ids)\n",
        "\n",
        "    return features\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def seed_everything(seed=123):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d1lyr6bp0sZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7149d6ae-5103-428c-9d49-164125cd42bb"
      },
      "source": [
        "# Initializing the BERT Model \n",
        "model_name = \"bert\"\n",
        "pretrained_model_name = \"bert-base-uncased\"\n",
        "n_classes = 1\n",
        "\n",
        "config_class, model_class, tokenizer_class = BertConfig, BertForSequenceClassification, BertTokenizer\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_model_name, do_lower_case=True)\n",
        "model = model_class.from_pretrained(pretrained_model_name, num_labels=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 70813.81B/s]\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 425680.98B/s]\n",
            "100%|██████████| 440473133/440473133 [00:37<00:00, 11778741.08B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVG-lgz01xzX",
        "colab_type": "code",
        "outputId": "6394db9e-2aee-4b2e-ff99-44143900a803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "\n",
        "# Get the maximum number of words\n",
        "# Find the number of words in user review\n",
        "train_df['length']= train_df.user_review.str.split().apply(len)\n",
        "test_df['length'] = test_df.user_review.str.split().apply(len)\n",
        "valid_df['length'] = valid_df.user_review.str.split().apply(len)\n",
        "train_df['user_review'] = train_df['user_review'].str.lower()\n",
        "test_df['user_review'] = test_df['user_review'].str.lower()\n",
        "valid_df['user_review'] = valid_df['user_review'].str.lower()\n",
        "max_length =  max(train_df['length'].max(),test_df['length'].max(),valid_df['length'].max()) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4QfLHeup0sb",
        "colab_type": "code",
        "outputId": "dc4fcdf8-59a8-4986-b714-655408e6bbf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "# Converting the data into required format\n",
        "#max_length = \n",
        "train_df[\"user_review\"] = train_df[\"user_review\"].astype(str).fillna(\"NA\")\n",
        "train_features = convert_text_to_features(train_df[\"user_review\"], tokenizer, max_length=max_length)\n",
        "\n",
        "valid_df[\"user_review\"] = valid_df[\"user_review\"].astype(str).fillna(\"NA\")\n",
        "valid_features = convert_text_to_features(valid_df[\"user_review\"], tokenizer, max_length=max_length)\n",
        "\n",
        "test_df[\"user_review\"] = test_df[\"user_review\"].astype(str).fillna(\"NA\")\n",
        "test_features = convert_text_to_features(test_df[\"user_review\"], tokenizer, max_length=max_length)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Writing example 0\n",
            "*** Example ***\n",
            "input_ids: 101 12873 12873 2121 1045 2134 2102 2066 1996 2678 2129 2071 2035 3312 2015 3428 2022 1997 1037 2367 2679 2024 2057 2667 2000 2022 10317 6149 2030 2054 2036 1045 4299 2123 4890 2018 2921 2010 3797 2006 1045 2001 2357 2006 2011 2010 15892 3108 1045 2031 2464 2023 2864 3807 2011 2967 2060 2084 2123 4890 1998 2522 1998 5632 2009 2061 2172 2062 2507 2009 2039 2123 4890 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Writing example 10000\n",
            "Writing example 20000\n",
            "Writing example 30000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Writing example 0\n",
            "*** Example ***\n",
            "input_ids: 101 1996 3143 2332 6919 6268 1997 12280 2147 2013 1996 2220 2000 2345 2086 22074 1996 9849 1999 3405 2974 2058 2010 2476 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Writing example 0\n",
            "*** Example ***\n",
            "input_ids: 101 2307 3729 2026 8403 6986 2038 2028 1997 1996 2307 5755 1997 2014 4245 1045 2031 7791 2000 2023 3729 2005 2086 1998 1045 2145 2293 2009 2043 10047 1999 1037 2204 6888 2009 3084 2033 2514 2488 1037 2919 6888 2074 9345 17822 8520 2066 5699 1999 1996 4542 2023 3729 2074 1051 18153 2229 2166 2955 2024 18414 16846 24646 4609 5582 1998 4581 2074 3102 2028 1997 2166 2015 5023 20296 2023 2003 1037 5532 8842 3729 1999 2026 2338 2339 2016 2196 2081 2009 2502 2003 2074 3458 2033 2296 7292 1045 2377 2023 2053 3043 2304 2317 2402 2214 3287 2931 7955 2758 2028 2518 2040 2001 2008 4823 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Writing example 10000\n",
            "Writing example 20000\n",
            "Writing example 30000\n",
            "Writing example 40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqsAqpJCp0se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert dataset to tensor format\n",
        "\n",
        "X = torch.tensor(train_features[0], dtype=torch.long)\n",
        "X_mask = torch.tensor(train_features[1], dtype=torch.long)\n",
        "X_seg_ids = torch.tensor(train_features[2], dtype=torch.long)\n",
        "y = train_df[\"user_rating\"].values\n",
        "y = torch.tensor(y[:,np.newaxis], dtype=torch.float32)\n",
        "\n",
        "X_valid = torch.tensor(valid_features[0], dtype=torch.long)\n",
        "X_mask_valid = torch.tensor(valid_features[1], dtype=torch.long)\n",
        "X_seg_ids_valid = torch.tensor(valid_features[2], dtype=torch.long)\n",
        "valid_y = valid_df[\"user_rating\"].values\n",
        "valid_y = torch.tensor(valid_y[:,np.newaxis], dtype=torch.float32)\n",
        "\n",
        "test_X = torch.tensor(test_features[0], dtype=torch.long)\n",
        "test_X_mask = torch.tensor(test_features[1], dtype=torch.long)\n",
        "test_X_seg_ids = torch.tensor(test_features[2], dtype=torch.long)\n",
        "test_y = test_df[\"user_rating\"].values\n",
        "test_y = torch.tensor(test_y[:,np.newaxis], dtype=torch.float32)\n",
        "\n",
        "# Create the dataloader for the train, valid and test dataset\n",
        "batch_size = 8\n",
        "train_dataset = data.TensorDataset(X, X_mask, X_seg_ids, y)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_dataset = data.TensorDataset(X_valid, X_mask_valid, X_seg_ids_valid, valid_y)\n",
        "valid_loader = data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = data.TensorDataset(test_X, test_X_mask, test_X_seg_ids,test_y)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttHeg_0hp0sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the model parameters\n",
        "accumulation_steps = 1\n",
        "n_epochs = 1\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "num_train_optimization_steps = int(n_epochs*len(train_dataset)/batch_size/accumulation_steps)\n",
        "num_warmup_steps = int(0.05*num_train_optimization_steps)\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)\n",
        "scheduler = WarmupLinearSchedule( optimizer,\n",
        "                                 warmup_steps=num_warmup_steps,\n",
        "                                 t_total=num_train_optimization_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGsdhGc5p0si",
        "colab_type": "code",
        "outputId": "ed48ae55-8271-4981-e1e0-7c64f3d3ee54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "fceaa4b2961c4a7d8d6f0b160fabe43a",
            "63f3ed0ae9b5420d9d09252bb7a6a0d3",
            "7b0adc75c4da4ce5aec8ccdee58a1a5d",
            "449b5b038e6f47619fad2a7d23ed32ad",
            "ec304675b7d8477cb92d856faeeddfa7",
            "ef73c568cdfa44caa360196042f29e24",
            "de388cb03bea446c866f6d5ac4aee771",
            "06c241756172408b8cf72064afee8c7a"
          ]
        }
      },
      "source": [
        "# Train the model\n",
        "import os\n",
        "seed_everything()\n",
        "model.to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "count = 0\n",
        "val_acc = []\n",
        "train_acc = []\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    print(epoch)\n",
        "    count = 0\n",
        "    j = 0 \n",
        "    lent=len(train_loader)\n",
        "    for x_batch, x_mask, x_seg_ids, y_batch in tn(train_loader):\n",
        "        #print(j,lent)\n",
        "        outputs = model(x_batch.to(device),\n",
        "                        attention_mask=x_mask.to(device),\n",
        "                        token_type_ids=x_seg_ids.to(device),\n",
        "                        labels=None)\n",
        "        y_pred = outputs[0]\n",
        "        loss = loss_fn(y_pred, y_batch.to(device))\n",
        "        loss.backward()\n",
        "        scheduler.step()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    model.eval()\n",
        "    for x_batch, x_mask, x_seg_ids, y_batch in valid_loader:\n",
        "        #print(j,lent)\n",
        "        outputs = model(x_batch.to(device),\n",
        "                        attention_mask=x_mask.to(device),\n",
        "                        token_type_ids=x_seg_ids.to(device),\n",
        "                        labels=None)\n",
        "        pred = sigmoid(outputs[0].detach().cpu().numpy())\n",
        "        pred = pred.squeeze()\n",
        "        positive_threshold = pred > 0.5\n",
        "        negative_threshold = pred <= 0.5\n",
        "        pred[positive_threshold] = 1\n",
        "        pred[negative_threshold] = 0 \n",
        "        y_batch = y_batch.squeeze().numpy()\n",
        "        val_acc.append((pred == y_batch).mean())\n",
        "\n",
        "    for x_batch, x_mask, x_seg_ids, y_batch in train_loader:\n",
        "        #print(j,lent)\n",
        "        outputs = model(x_batch.to(device),\n",
        "                        attention_mask=x_mask.to(device),\n",
        "                        token_type_ids=x_seg_ids.to(device),\n",
        "                        labels=None)\n",
        "        pred = sigmoid(outputs[0].detach().cpu().numpy())\n",
        "        pred = pred.squeeze()\n",
        "        positive_threshold = pred > 0.5\n",
        "        negative_threshold = pred <= 0.5\n",
        "        pred[positive_threshold] = 1\n",
        "        pred[negative_threshold] = 0 \n",
        "        y_batch = y_batch.squeeze().numpy()\n",
        "        train_acc.append((pred == y_batch).mean())\n",
        "    print(\"validation accuracy = \",np.mean(val_acc),\"training accuracy = \",np.mean(train_acc))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fceaa4b2961c4a7d8d6f0b160fabe43a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation accuracy =  0.9468 training accuracy =  0.976775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvlGJWdAp0sn",
        "colab_type": "code",
        "outputId": "f78c34f6-9137-4f9c-9343-682fe97d24ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2fa2881ff349451da51abfaf168c14ad",
            "4deed147c57043968338de2054a02cc3",
            "6d3853144ad349ceb3d81c4f99a93496",
            "bc073690aba642dca728aa7287661c85",
            "cbeb99f78dcf4130972727373cb62312",
            "e9e7aa7c8a644d36bb01936062ea3bfa",
            "00385e885a3a428a98fb29f78381ecf4",
            "704b970870a24f9ab933ba2377df6172"
          ]
        }
      },
      "source": [
        "# Predict the test dataset\n",
        "predict_list = []\n",
        "expected_list = []\n",
        "model.eval()\n",
        "for i, (x_batch, x_mask, x_seg_ids,y_batch) in enumerate(tn(test_loader)):\n",
        "    outputs = model(x_batch.to(device),\n",
        "                    attention_mask=x_mask.to(device),\n",
        "                    token_type_ids=x_seg_ids.to(device),\n",
        "                    labels=None)\n",
        "    pred = sigmoid(outputs[0].detach().cpu().numpy())\n",
        "    pred = pred.squeeze()\n",
        "    positive_threshold = pred > 0.5\n",
        "    negative_threshold = pred <= 0.5\n",
        "    pred[positive_threshold] = 1\n",
        "    pred[negative_threshold] = 0\n",
        "    predict_list.extend(pred.tolist())\n",
        "    expected_list.extend(y_batch.cpu().detach().numpy().tolist())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fa2881ff349451da51abfaf168c14ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS66RpKvQ2Ua",
        "colab_type": "code",
        "outputId": "f01bb0de-7aa4-4d98-ca48-b4230d094f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(classification_report(expected_list,predict_list))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.95      0.95     24626\n",
            "         1.0       0.95      0.95      0.95     25374\n",
            "\n",
            "    accuracy                           0.95     50000\n",
            "   macro avg       0.95      0.95      0.95     50000\n",
            "weighted avg       0.95      0.95      0.95     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}